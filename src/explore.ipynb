{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# WEB SCRAPING WORKFLOW"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'bs4'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# STEP 0 â€” IMPORTS AND HELPER FUNCTIONS\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Web Scraping Workflow (Jupyter Notebook Version)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 1) Essential imports\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m                      \u001b[38;5;66;03m# For HTTP requests\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup        \u001b[38;5;66;03m# For parsing HTML\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m                  \u001b[38;5;66;03m# For tabular data handling\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m                          \u001b[38;5;66;03m# For timing and delays\u001b[39;00m\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bs4'"
                    ]
                }
            ],
            "source": [
                "# ===============================================================\n",
                "# STEP 0 â€” IMPORTS AND HELPER FUNCTIONS\n",
                "# Web Scraping Workflow (Jupyter Notebook Version)\n",
                "# ===============================================================\n",
                "\n",
                "# ---------------------------\n",
                "# 1) Essential imports\n",
                "# ---------------------------\n",
                "\n",
                "import requests                      # For HTTP requests\n",
                "from bs4 import BeautifulSoup        # For parsing HTML\n",
                "import pandas as pd                  # For tabular data handling\n",
                "import time                          # For timing and delays\n",
                "from typing import List, Optional    # Type hinting for clarity\n",
                "\n",
                "# ---------------------------\n",
                "# 2) Helper Functions\n",
                "# ---------------------------\n",
                "\n",
                "# Sends an HTTP GET request and returns the HTML content\n",
                "#  - If something fails, returns None and prints a detailed error.\n",
                "def test_connection(url: str, timeout: int = 10) -> Optional[str]:\n",
                "    print(f\"ðŸ”Ž Testing connection to: {url}\")\n",
                "    headers = {\n",
                "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
                "    }\n",
                "    try:\n",
                "        response = requests.get(url, timeout=timeout, headers=headers)\n",
                "        response.raise_for_status()  # Raises HTTP errors if present\n",
                "        print(\"âœ… Connection successful.\")\n",
                "        return response.text\n",
                "    except requests.exceptions.RequestException as e:\n",
                "        print(f\"âŒ Connection failed:\\n{e}\")\n",
                "        return None\n",
                "\n",
                "# Parses raw HTML into a BeautifulSoup object\n",
                "def parse_html(html_text: str) -> BeautifulSoup:\n",
                "    return BeautifulSoup(html_text, \"html.parser\")\n",
                "\n",
                "# Prints a short preview of the HTML to understand the content\n",
                "def safe_print_preview(html_text: str, max_chars: int = 500):\n",
                "    print(\"\\nðŸ“„ HTML preview:\")\n",
                "    print(\"----------------------------------------\")\n",
                "    print(html_text[:max_chars])\n",
                "    print(\"----------------------------------------\")\n",
                "    print(f\"(showing first {max_chars} characters)\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ===============================================================\n",
                "# STEP 1 â€” URL Input + Connection Test + HTML Preview\n",
                "# ===============================================================\n",
                "\n",
                "# Ask user for a URL (manual input)\n",
                "url = input(\"ðŸ”— Enter the URL you want to scrape:\\n>>> \")\n",
                "\n",
                "print(\"\\n==============================================\")\n",
                "print(\"STEP 1 â€” Connecting to URL\")\n",
                "print(\"==============================================\\n\")\n",
                "\n",
                "# 1) Test the connection and retrieve HTML\n",
                "html_text = test_connection(url)\n",
                "\n",
                "# 2) Stop the workflow if the connection failed\n",
                "if html_text is None:\n",
                "    print(\"\\nâ›” STEP 1 failed. Fix the URL or your connection and try again.\")\n",
                "else:\n",
                "    print(\"\\nðŸ“¥ Raw HTML downloaded successfully.\")\n",
                "    safe_print_preview(html_text)\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
